% This document is based on http://math.shinshu-u.ac.jp/~hanaki/beamer/beamer.html
\documentclass[dvipdfmx,cjk]{beamer}
%\documentclass[dvipdfm,cjk]{beamer} % オプションは環境や利用するプログラムによって変える
%\documentclass[dvips,cjk]{beamer}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{latexsym}


% しおり（PDF にしたときの目次）の文字化け防止
\AtBeginDvi{\special{pdf:tounicode 90ms-RKSJ-UCS2}}
%\AtBeginDvi{\special{pdf:tounicode EUC-UCS2}}

% 右下のアイコンを消す
\setbeamertemplate{navigation symbols}{}

% テーマ
\usetheme{CambridgeUS}
%\usetheme{Boadilla}           %% Beamer のディレクトリの中の
%\usetheme{Madrid}             %% beamerthemeCambridgeUS.sty を指定
%\usetheme{Antibes}            %% 色々と試してみるといいだろう
%\usetheme{Montpellier}        %% サンプルが beamer\doc に色々とある。
%\usetheme{Berkeley}
%\usetheme{Goettingen}
%\usetheme{Singapore}
%\usetheme{Szeged}

\usecolortheme{rose}          %% colortheme を選ぶと色使いが変わる
%\usecolortheme{albatross}

%\useoutertheme{shadow}                 %% 箱に影をつける
\usefonttheme{professionalfonts}       %% 数式の文字を通常の LaTeX と同じにする

%\setbeamercovered{transparent}         %% 消えている文字をうっすらと表示する
%\setbeamertemplate{theorems}[numbered]  %% 定理に番号をつける
\newtheorem{thm}{Theorem}[section]
\newtheorem{proposition}[thm]{Proposition}
\theoremstyle{example}
\newtheorem{exam}[thm]{Example}
\newtheorem{remark}[thm]{Remark}
\newtheorem{question}[thm]{Question}
\newtheorem{prob}[thm]{Problem}
\newtheorem{rev}[thm]{Review}
\DeclareMathOperator{\argmin}{argmin}

% メタ情報
\begin{document}
\title[]{Data Science and Machine Learning}
\author[]{照屋 佑喜仁}
\institute[]{}
\date{\today}

% タイトルスライド
\begin{frame}
    \titlepage
\end{frame}

% 目次（\section 名が自動で挿入される）
\begin{frame}
    \tableofcontents
\end{frame}

\section{2.4 Tradeoffs in Statical Learning}
\subsection{教師あり学習の技術}
\begin{frame}
    \frametitle{教師あり学習}
    \begin{itemize}
        \item 教師あり学習における機械学習の技術
              \begin{itemize}
                  \item generalization risk(2.5)あるいはexpected generalization risk(2.6)をできるだけ小さくする
                  \item できるだけ少ない計算リソースで
              \end{itemize}
        \item これを達成するために，適切な予測関数の集合$\mathcal{G}$を選ぶ必要がある．この選び方は下のような要因によって決まる．
              \begin{itemize}
                  \item 集合の複雑さ(最適な予測関数$g^*$を適切に近似，あるいは含むのに十分に複雑(豊か)か？)
                  \item (2.4)の最適化によって学習者を訓練する容易さ
                  \item 集合$\mathcal{G}$において，training loss(2.3)がrisk(2.1)をどれだけ正確に推定するか
                  \item 連続なのか，分類なのか……
              \end{itemize}
    \end{itemize}
\end{frame}

\subsection{Tradeoff}
\begin{frame}
    \frametitle{Tradeoff}
    \begin{itemize}
        \item 集合$\mathcal{G}$の選択は，通常トレードオフを伴う
              \begin{itemize}
                  \item 単純な$\mathcal{G}$からの学習器は早く訓練できるが，上手く近似できない可能性
                  \item $g^*$を含むような豊かな$\mathcal{G}$からの学習器は多くの計算リソースを必要とする可能性
              \end{itemize}
        \item モデルの複雑さ，計算の単純さ，推定の制度の関係を見るために2つのtradeoffについて考えていく
              \begin{itemize}
                  \item the approxiation-estimation tradeoff(近似-推定トレードオフ)
                  \item the bias-variance tradeoff(バイアス-分散トレードオフ)
              \end{itemize}
    \end{itemize}
    今，generalization risk(2.5)を３つの要素に分解して考える．
    \begin{align*}
        \ell(g^\mathcal{G}_\tau)=\underbrace{\ell^*}_\text{irreducible risk}+\underbrace{\ell(g^\mathcal{G})-\ell^*}_\text{approximation error}+\underbrace{\ell(g^\mathcal{G}_\tau)-\ell(g^\mathcal{G})}_\text{statistical error} \tag{2.16}
    \end{align*}
\end{frame}
\subsection{irreducible risk, approxiation error, statistical error}
\begin{frame}
    \frametitle{irreducible risk，approximation error}
    \begin{align*}
        \ell(g^\mathcal{G}_\tau)=\underbrace{\ell^*}_\text{irreducible risk}+\underbrace{\ell(g^\mathcal{G})-\ell^*}_\text{approximation error}+\underbrace{\ell(g^\mathcal{G}_\tau)-\ell(g^\mathcal{G})}_\text{statistical error}\tag{2.16}
    \end{align*}
    \begin{itemize}
        \item \alert{$\ell^*$}は$\ell(g^*)$で定義されるirreducible risk(還元不能リスク)．どの学習器も$\ell^*$より小さいリスクで予測することはできない．
        \item \alert{$g^\mathcal{G}$}は$\argmin_{g\in\mathcal{G}}\ell(g)$で定義される，$\mathcal{G}$内で最も最良の学習器．
        \item \alert{$\ell(g^\mathcal{G})-\ell^*$}はapproximation error(近似誤差)．irreducible riskと$\mathcal{G}$のなかで最良の予測関数のriskの差を見ている．
              \begin{itemize}
                  \item 適切な$\mathcal{G}$を選び, その上で$\ell(g)$を最小化するのは，単純に数値解析と関数解析の問題となる(ここで訓練データ$\tau$は登場しないから)
                  \item $\mathcal{G}$が$g^*$を含まなければ近似誤差は任意に小さく出来ずriskを大きくする要因となる
                  \item 近似誤差を減らす唯一の方法は，$\mathcal{G}$を大きくしてより多くの関数を含めること
              \end{itemize}
    \end{itemize}
\end{frame}
\begin{frame}
    \frametitle{statical (estimation) error}
    \begin{align*}
        \ell(g^\mathcal{G}_\tau)=\underbrace{\ell^*}_\text{irreducible risk}+\underbrace{\ell(g^\mathcal{G})-\ell^*}_\text{approximation error}+\underbrace{\ell(g^\mathcal{G}_\tau)-\ell(g^\mathcal{G})}_\text{statistical error}\tag{2.16}
    \end{align*}
    \begin{itemize}
        \item \alert{$\ell(g^\mathcal{G}_\tau)-\ell(g^\mathcal{G})$}はstatistical(estimation) error(統計的(推定)誤差)．訓練セット$\tau$に依存．特に，学習器$g^\mathcal{G}_\tau$が$\mathcal{G}$の最良の予測関数$g^\mathcal{G}$をどれだけ上手く推定しているかに依存している．\\(良い予測器なら)この誤差は訓練サイズが無限大に近づくにつれて(確率的に，または期待値として)0に収束するはずである．
    \end{itemize}
\end{frame}
\subsection{approximation-estimation tradeoff}
\begin{frame}
    \frametitle{approximation-estimation tradeoff}
    approximation-estimation tradeoff(近似-推定トレードオフ)は，２つの相反する要求を対立させる．
    \begin{itemize}
        \item $\mathcal{G}$が十分にシンプルで，統計的誤差が大きくなりすぎない必要がある．（推定しやすい？）
        \item $\mathcal{G}$が十分に充実して，近似誤差が小さいことを保証する必要がある．（$g^*$をできれば見つけたい？）
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{2乗誤差損失でのリスクを解釈してみる}
    2乗誤差損失のリスクは$\ell(g^\mathcal{G}_\tau)=\mathbb{E}\left[(Y-g^\mathcal{G}_\tau(\boldsymbol{X}))^2\right]$となる．このとき，最適な予測関数は$g^*(\boldsymbol{x})=\mathbb{E}\left[Y\mid \boldsymbol{X}=\boldsymbol{x}\right]$で与えられるのであった．(theorem2.1)\\
    このとき，分解(2.16)は以下のように解釈できる．
    \begin{itemize}
        \item $\ell^*=\mathbb{E}\left[(Y-g^*(\boldsymbol{X}))^2\right]$は還元不能誤差であり，これより小さい期待2乗誤差の予測関数はない．
        \item 近似誤差$\ell(g^\mathcal{G})-\ell(g^*)$は$\mathbb{E}\left[g^\mathcal{G}(\boldsymbol{X})-g^*(\boldsymbol{X})^2\right]$に等しい(excrcise2)．つまり，最適予測値と$\mathcal{G}$内の最適予測値との間の２乗誤差の期待値として解釈できる．
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{２乗誤差損失でのリスクを解釈してみる}
    \begin{itemize}
        \item 統計的誤差$\ell(g^\mathcal{G}_\tau)-\ell(g^\mathcal{G})$に関しては$\mathcal{G}$が線形関数の集合である場合を除いて，期待２乗誤差(mean squared error 平均2乗誤差ともいう)としての直接的な解釈は存在しない．\\
              $\mathcal{G}$が線形関数集合の場合，関数$g(\boldsymbol{x})$はあるベクトル$\boldsymbol{\beta}$に対して$g(\boldsymbol{x})=\boldsymbol{x}^T\boldsymbol{\beta}$と表すことができ，統計的誤差は$\mathbb{E}\left[(g^\mathcal{G}_\tau(\boldsymbol{X})-g^\mathcal{G}(\boldsymbol{X}))^2\right]$となる(excercise3)．
    \end{itemize}
    以上より，２乗誤差損失を用いる場合，線形関数集合$\mathcal{G}$に対するgeneralization riskは
    \begin{align*}
        \ell(g^\mathcal{G}_\tau) & =\mathbb{E}\left[(g^\mathcal{G}_\tau(\boldsymbol{X})-Y)^2\right] \\&=\ell^*+\underbrace{\mathbb{E}\left[g^\mathcal{G}(\boldsymbol{X})-g^*(\boldsymbol{X})^2\right]}_\text{近似誤差}+\underbrace{\mathbb{E}\left[(g^\mathcal{G}_\tau(\boldsymbol{X})-g^\mathcal{G}(\boldsymbol{X}))^2\right]}_\text{統計的誤差}
    \end{align*}
    統計的誤差だけが訓練データに依存する唯一の項であることに注意．
\end{frame}

\subsection{excercise2}
\begin{frame}
    \frametitle{excercise2}
    保留していた証明を行う．まず，
    \begin{align*}
        \ell(g^\mathcal{G})-\ell(g^*)=\mathbb{E}\left[(g^\mathcal{G}(\boldsymbol{X})-g^*(\boldsymbol{X}))^2\right]
    \end{align*}
    を示す．
    \begin{proof}
        \begin{align*}
            \ell(g^\mathcal{G}) & =\mathbb{E}\left[(Y-g^\mathcal{G}(\boldsymbol{X}))^2\right] \quad \text{(2乗誤差を採用したときの定義)}                                                                                                   \\
                                & =\mathbb{E}\left[\left\{Y-g^*(\boldsymbol{X})+g^*(\boldsymbol{X})-g^\mathcal{G}(\boldsymbol{X})\right\}^2\right]                                                                            \\
                                & =\underbrace{\mathbb{E}\left[\left\{Y-g^*(\boldsymbol{X})\right\}^2\right]}_\text{$\ell(g^*)$の定義}+\mathbb{E}\left[\left\{g^*(\boldsymbol{X})-g^\mathcal{G}(\boldsymbol{X})\right\}^2\right] \\
                                & \qquad-\underbrace{2\mathbb{E}\left[\left\{Y-g^*(\boldsymbol{X})\right\}\left\{g^*(\boldsymbol{X})-g^\mathcal{G}(\boldsymbol{X})\right\}\right]}_\text{$\bigstar$}
        \end{align*}
        \renewcommand{\qedsymbol}{}
    \end{proof}
\end{frame}

\begin{frame}
    \frametitle{excercise2}
    \begin{proof}
        ここで，前々回のTheorem2.1の証明と同様の議論により$\bigstar=0$となるので，
        \begin{align*}
            \ell(g^\mathcal{G})-\ell(g^*)=\mathbb{E}\left[(g^\mathcal{G}(\boldsymbol{X})-g^*(\boldsymbol{X}))^2\right]
        \end{align*}
        を得る．
    \end{proof}
    \begin{remark}[tower property, taking out what is known]
        tower property:
        \begin{align*}
            \mathbb{E}[\mathbb{E}[Y|X]] = \mathbb{E}[Y]
        \end{align*}
        taking out what is known:
        \begin{align*}
            \mathbb{E}[XY|X]=X\mathbb{E}[Y|X]
        \end{align*}
    \end{remark}
\end{frame}
\begin{frame}
    \frametitle{参考(前々回のスライド)}
    \begin{proof}
        定義より，
        \begin{align*}
            \mathbb{E}[Y-g^*(\boldsymbol{X})|\boldsymbol{X}] & =\int_\mathbb{R}(y-g^*(\boldsymbol{x}))f_{Y|\boldsymbol{X}}(y|\boldsymbol{x})dy                                                      \\
                                                             & =\int_\mathbb{R}yf_{Y|\boldsymbol{X}}(y|\boldsymbol{x})dy-\int_\mathbb{R}g^*(\boldsymbol{x})f_{Y|\boldsymbol{X}}(y|\boldsymbol{x})dy \\
                                                             & = \mathbb{E}[Y|\boldsymbol{X}]-\mathbb{E}[Y|X]\int_\mathbb{R}\frac{f(x,y)}{f_X(x)}dy                                                 \\
                                                             & =0                                                                                                                                   \\
            \because\int_\mathbb{R}\frac{f(x,y)}{f_X(x)}dy   & =\frac{1}{f_X(x)}\int_\mathbb{R}f(x,y)dy                                                                                             \\
                                                             & =\frac{1}{f_X(x)}f_X(x)=1
        \end{align*}
        \renewcommand{\qedsymbol}{}
    \end{proof}
\end{frame}

\subsection{exercise3}
\begin{frame}
    \frametitle{excercise3}
    次に以下を示す．
    \begin{align*}
        \ell(g^\mathcal{G}_\tau)-\ell(g^\mathcal{G})=\mathbb{E}\left[(g^\mathcal{G}_\tau(\boldsymbol{X})-g^\mathcal{G}(\boldsymbol{X}))^2\right]
    \end{align*}
    \begin{proof}
        \begin{align*}
            \ell(g^\mathcal{G}_\tau) & =\mathbb{E}\left[\left\{Y-g^\mathcal{G}_\tau(\boldsymbol{X})\right\}^2\right]                                                             \\
                                     & =\mathbb{E}\left[\left\{Y-g^*(\boldsymbol{X})+g^*(\boldsymbol{X})-g^\mathcal{G}_\tau(\boldsymbol{X})\right\}^2\right]                     \\
                                     & =\ell(g^*)+\underbrace{\mathbb{E}\left[\left\{g^*(\boldsymbol{X})-g^\mathcal{G}_\tau(\boldsymbol{X})\right\}^2\right]}_\text{$\clubsuit$}
        \end{align*}
        \renewcommand{\qedsymbol}{}
    \end{proof}
\end{frame}

\begin{frame}
    \frametitle{excercise3}
    \begin{proof}
        ここで，
        \begin{align*}
            \clubsuit & = \mathbb{E}\left[\left\{g^*(\boldsymbol{X})-g^\mathcal{G}(\boldsymbol{X})+g^\mathcal{G}(\boldsymbol{X})-g^\mathcal{G}_\tau(\boldsymbol{X})\right\}^2\right]                                        \\
                      & =\mathbb{E}\left[\left\{g^*(\boldsymbol{X})-g^\mathcal{G}(\boldsymbol{X})\right\}^2\right]+\mathbb{E}\left[\left\{g^\mathcal{G}(\boldsymbol{X})-g^\mathcal{G}_\tau(\boldsymbol{X})\right\}^2\right] \\
                      & \qquad -2\mathbb{E}\left[\left\{g^*(\boldsymbol{X})-g^\mathcal{G}(\boldsymbol{X})\right\}\left\{g^\mathcal{G}(\boldsymbol{X})-g^\mathcal{G}_\tau(\boldsymbol{X})\right\}\right]
        \end{align*}
    \end{proof}
\end{frame}
\end{document}
